{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "4e5a4a65-8bc6-4c44-b8ab-30a7ee70b2a0",
      "cell_type": "markdown",
      "source": "# Iris Species Classification using Decision Tree Classifier\n# A complete machine learning pipeline with scikit-learn",
      "metadata": {}
    },
    {
      "id": "4010698b-048a-46ec-b970-111a76e1894b",
      "cell_type": "code",
      "source": "import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom sklearn import tree",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 18
    },
    {
      "id": "b5363c4d-14b3-439a-a868-73cbebb86225",
      "cell_type": "code",
      "source": "# Load and explore the data\nprint(\"=\" * 60)\nprint(\"IRIS SPECIES CLASSIFICATION - DECISION TREE CLASSIFIER\")\nprint(\"=\" * 60)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "============================================================\nIRIS SPECIES CLASSIFICATION - DECISION TREE CLASSIFIER\n============================================================\n"
        }
      ],
      "execution_count": 4
    },
    {
      "id": "cae98478-25f8-4a89-a2a7-fb3b2e0eb624",
      "cell_type": "code",
      "source": "df = pd.read_csv('Iris.csv')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "id": "6b2ba435-6f5b-421a-8845-24a54389e155",
      "cell_type": "code",
      "source": "print(\"\\n1. DATASET OVERVIEW\")\nprint(\"-\" * 30)\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Columns: {list(df.columns)}\")\nprint(\"\\nFirst 5 rows:\")\nprint(df.head())\n\nprint(\"\\nDataset info:\")\nprint(df.info())\n\nprint(\"\\nSpecies distribution:\")\nprint(df['Species'].value_counts())",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n1. DATASET OVERVIEW\n------------------------------\nDataset shape: (150, 6)\nColumns: ['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species']\n\nFirst 5 rows:\n   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n0   1            5.1           3.5            1.4           0.2  Iris-setosa\n1   2            4.9           3.0            1.4           0.2  Iris-setosa\n2   3            4.7           3.2            1.3           0.2  Iris-setosa\n3   4            4.6           3.1            1.5           0.2  Iris-setosa\n4   5            5.0           3.6            1.4           0.2  Iris-setosa\n\nDataset info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 150 entries, 0 to 149\nData columns (total 6 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   Id             150 non-null    int64  \n 1   SepalLengthCm  150 non-null    float64\n 2   SepalWidthCm   150 non-null    float64\n 3   PetalLengthCm  150 non-null    float64\n 4   PetalWidthCm   150 non-null    float64\n 5   Species        150 non-null    object \ndtypes: float64(4), int64(1), object(1)\nmemory usage: 6.5+ KB\nNone\n\nSpecies distribution:\nSpecies\nIris-setosa        50\nIris-versicolor    50\nIris-virginica     50\nName: count, dtype: int64\n"
        }
      ],
      "execution_count": 6
    },
    {
      "id": "cc9c490f-5d17-4224-ae2b-7362839b1333",
      "cell_type": "code",
      "source": "print(\"\\n\\n2. DATA PREPROCESSING\")\nprint(\"-\" * 30)\n\n# Check for missing values\nprint(\"Missing values per column:\")\nprint(df.isnull().sum())\n\n# Check for duplicates\nprint(f\"\\nDuplicate rows: {df.duplicated().sum()}\")\n\n# Basic statistics\nprint(\"\\nBasic statistics for numerical features:\")\nprint(df.describe())\n\n# Separate features and target\nX = df.drop(['Id', 'Species'], axis=1)  # Remove ID column and target\ny = df['Species']\n\nprint(f\"\\nFeatures shape: {X.shape}\")\nprint(f\"Target shape: {y.shape}\")\n\n# Encode the target labels (Species)\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\nprint(f\"\\nLabel encoding mapping:\")\nfor i, species in enumerate(label_encoder.classes_):\n    print(f\"{species}: {i}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\n2. DATA PREPROCESSING\n------------------------------\nMissing values per column:\nId               0\nSepalLengthCm    0\nSepalWidthCm     0\nPetalLengthCm    0\nPetalWidthCm     0\nSpecies          0\ndtype: int64\n\nDuplicate rows: 0\n\nBasic statistics for numerical features:\n               Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\ncount  150.000000     150.000000    150.000000     150.000000    150.000000\nmean    75.500000       5.843333      3.054000       3.758667      1.198667\nstd     43.445368       0.828066      0.433594       1.764420      0.763161\nmin      1.000000       4.300000      2.000000       1.000000      0.100000\n25%     38.250000       5.100000      2.800000       1.600000      0.300000\n50%     75.500000       5.800000      3.000000       4.350000      1.300000\n75%    112.750000       6.400000      3.300000       5.100000      1.800000\nmax    150.000000       7.900000      4.400000       6.900000      2.500000\n\nFeatures shape: (150, 4)\nTarget shape: (150,)\n\nLabel encoding mapping:\nIris-setosa: 0\nIris-versicolor: 1\nIris-virginica: 2\n"
        }
      ],
      "execution_count": 7
    },
    {
      "id": "0b632655-cd30-4def-857e-662a982a1839",
      "cell_type": "code",
      "source": "\n# Step 3: Split the data\nprint(\"\\n\\n3. DATA SPLITTING\")\nprint(\"-\" * 30)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y_encoded, \n    test_size=0.2, \n    random_state=42, \n    stratify=y_encoded  # Ensure balanced split across all classes\n)\n\nprint(f\"Training set shape: {X_train.shape}\")\nprint(f\"Test set shape: {X_test.shape}\")\nprint(f\"Training set class distribution: {np.bincount(y_train)}\")\nprint(f\"Test set class distribution: {np.bincount(y_test)}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\n3. DATA SPLITTING\n------------------------------\nTraining set shape: (120, 4)\nTest set shape: (30, 4)\nTraining set class distribution: [40 40 40]\nTest set class distribution: [10 10 10]\n"
        }
      ],
      "execution_count": 8
    },
    {
      "id": "4727a055-677e-4278-bca3-7e592581c9ca",
      "cell_type": "code",
      "source": "# Step 4: Train the Decision Tree Classifier\nprint(\"\\n\\n4. MODEL TRAINING\")\nprint(\"-\" * 30)\n\n# Initialize the Decision Tree Classifier\ndt_classifier = DecisionTreeClassifier(\n    random_state=42,\n    max_depth=5,  # Limit depth to prevent overfitting\n    min_samples_split=2,\n    min_samples_leaf=1\n)\n\n# Train the model\ndt_classifier.fit(X_train, y_train)\n\nprint(\"Decision Tree Classifier trained successfully!\")\nprint(f\"Tree depth: {dt_classifier.get_depth()}\")\nprint(f\"Number of leaves: {dt_classifier.get_n_leaves()}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\n4. MODEL TRAINING\n------------------------------\nDecision Tree Classifier trained successfully!\nTree depth: 5\nNumber of leaves: 8\n"
        }
      ],
      "execution_count": 9
    },
    {
      "id": "e3e9bf9c-4d11-4d45-a5f0-b51f6ba668f0",
      "cell_type": "code",
      "source": "# Step 5: Make predictions\nprint(\"\\n\\n5. PREDICTIONS\")\nprint(\"-\" * 30)\n\n# Predictions on training set\ny_train_pred = dt_classifier.predict(X_train)\n\n# Predictions on test set\ny_test_pred = dt_classifier.predict(X_test)\n\nprint(\"Predictions completed!\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\n5. PREDICTIONS\n------------------------------\nPredictions completed!\n"
        }
      ],
      "execution_count": 10
    },
    {
      "id": "2b1abbe9-ae13-4f2b-8c47-81ca117a8471",
      "cell_type": "code",
      "source": "# Step 6: Model Evaluation\nprint(\"\\n\\n6. MODEL EVALUATION\")\nprint(\"-\" * 30)\n\n# Calculate accuracy\ntrain_accuracy = accuracy_score(y_train, y_train_pred)\ntest_accuracy = accuracy_score(y_test, y_test_pred)\n\nprint(f\"Training Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\nprint(f\"Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n\n# Calculate precision and recall (using weighted average for multiclass)\ntrain_precision = precision_score(y_train, y_train_pred, average='weighted')\ntrain_recall = recall_score(y_train, y_train_pred, average='weighted')\n\ntest_precision = precision_score(y_test, y_test_pred, average='weighted')\ntest_recall = recall_score(y_test, y_test_pred, average='weighted')\n\nprint(f\"\\nTraining Metrics:\")\nprint(f\"  Precision: {train_precision:.4f}\")\nprint(f\"  Recall: {train_recall:.4f}\")\n\nprint(f\"\\nTest Metrics:\")\nprint(f\"  Precision: {test_precision:.4f}\")\nprint(f\"  Recall: {test_recall:.4f}\")\n\n# Detailed classification report\nprint(\"\\n\\nDETAILED CLASSIFICATION REPORT (Test Set):\")\nprint(\"-\" * 50)\ntarget_names = label_encoder.classes_\nprint(classification_report(y_test, y_test_pred, target_names=target_names))\n\n# Confusion Matrix\nprint(\"\\nCONFUSION MATRIX (Test Set):\")\nprint(\"-\" * 30)\ncm = confusion_matrix(y_test, y_test_pred)\nprint(cm)\n\n# Pretty print confusion matrix with labels\ncm_df = pd.DataFrame(cm, index=target_names, columns=target_names)\nprint(\"\\nConfusion Matrix (with labels):\")\nprint(cm_df)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\n6. MODEL EVALUATION\n------------------------------\nTraining Accuracy: 1.0000 (100.00%)\nTest Accuracy: 0.9333 (93.33%)\n\nTraining Metrics:\n  Precision: 1.0000\n  Recall: 1.0000\n\nTest Metrics:\n  Precision: 0.9333\n  Recall: 0.9333\n\n\nDETAILED CLASSIFICATION REPORT (Test Set):\n--------------------------------------------------\n                 precision    recall  f1-score   support\n\n    Iris-setosa       1.00      1.00      1.00        10\nIris-versicolor       0.90      0.90      0.90        10\n Iris-virginica       0.90      0.90      0.90        10\n\n       accuracy                           0.93        30\n      macro avg       0.93      0.93      0.93        30\n   weighted avg       0.93      0.93      0.93        30\n\n\nCONFUSION MATRIX (Test Set):\n------------------------------\n[[10  0  0]\n [ 0  9  1]\n [ 0  1  9]]\n\nConfusion Matrix (with labels):\n                 Iris-setosa  Iris-versicolor  Iris-virginica\nIris-setosa               10                0               0\nIris-versicolor            0                9               1\nIris-virginica             0                1               9\n"
        }
      ],
      "execution_count": 11
    },
    {
      "id": "7c493697-43ae-4142-a2ec-4dfa44726d4e",
      "cell_type": "code",
      "source": "# Step 7: Feature Importance\nprint(\"\\n\\n7. FEATURE IMPORTANCE\")\nprint(\"-\" * 30)\n\nfeature_importance = dt_classifier.feature_importances_\nfeature_names = X.columns\n\n# Create a DataFrame for better visualization\nimportance_df = pd.DataFrame({\n    'Feature': feature_names,\n    'Importance': feature_importance\n}).sort_values('Importance', ascending=False)\n\nprint(\"Feature Importance Ranking:\")\nfor idx, row in importance_df.iterrows():\n    print(f\"{row['Feature']}: {row['Importance']:.4f}\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\n7. FEATURE IMPORTANCE\n------------------------------\nFeature Importance Ranking:\nPetalLengthCm: 0.5586\nPetalWidthCm: 0.4060\nSepalWidthCm: 0.0292\nSepalLengthCm: 0.0062\n"
        }
      ],
      "execution_count": 12
    },
    {
      "id": "01d38ae4-bb68-4ef9-b6ef-4f24a27df430",
      "cell_type": "code",
      "source": "# Step 8: Model Insights and Analysis\nprint(\"\\n\\n8. MODEL INSIGHTS\")\nprint(\"-\" * 30)\n\n# Per-class metrics\nprint(\"Per-class Performance Metrics:\")\nprecision_per_class = precision_score(y_test, y_test_pred, average=None)\nrecall_per_class = recall_score(y_test, y_test_pred, average=None)\n\nfor i, species in enumerate(target_names):\n    print(f\"{species}:\")\n    print(f\"  Precision: {precision_per_class[i]:.4f}\")\n    print(f\"  Recall: {recall_per_class[i]:.4f}\")\n\n# Prediction examples\nprint(f\"\\nSample Predictions (First 10 test samples):\")\nprint(\"Actual -> Predicted\")\nfor i in range(min(10, len(y_test))):\n    actual = label_encoder.inverse_transform([y_test[i]])[0]\n    predicted = label_encoder.inverse_transform([y_test_pred[i]])[0]\n    print(f\"{actual} -> {predicted}\")\n\n# Model parameters\nprint(f\"\\n\\nMODEL PARAMETERS:\")\nprint(\"-\" * 20)\nprint(f\"Max Depth: {dt_classifier.max_depth}\")\nprint(f\"Min Samples Split: {dt_classifier.min_samples_split}\")\nprint(f\"Min Samples Leaf: {dt_classifier.min_samples_leaf}\")\nprint(f\"Criterion: {dt_classifier.criterion}\")\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\n8. MODEL INSIGHTS\n------------------------------\nPer-class Performance Metrics:\nIris-setosa:\n  Precision: 1.0000\n  Recall: 1.0000\nIris-versicolor:\n  Precision: 0.9000\n  Recall: 0.9000\nIris-virginica:\n  Precision: 0.9000\n  Recall: 0.9000\n\nSample Predictions (First 10 test samples):\nActual -> Predicted\nIris-setosa -> Iris-setosa\nIris-virginica -> Iris-virginica\nIris-versicolor -> Iris-versicolor\nIris-versicolor -> Iris-versicolor\nIris-setosa -> Iris-setosa\nIris-versicolor -> Iris-versicolor\nIris-setosa -> Iris-setosa\nIris-setosa -> Iris-setosa\nIris-virginica -> Iris-virginica\nIris-versicolor -> Iris-versicolor\n\n\nMODEL PARAMETERS:\n--------------------\nMax Depth: 5\nMin Samples Split: 2\nMin Samples Leaf: 1\nCriterion: gini\n"
        }
      ],
      "execution_count": 13
    },
    {
      "id": "c311f2fc-9332-472f-8674-fa327b02717f",
      "cell_type": "code",
      "source": "# Step 9: Data Visualization\nprint(\"\\n\\n9. DATA VISUALIZATION\")\nprint(\"-\" * 30)\n\n# Set up plotting style\nplt.style.use('default')\n\n# Plot 1: Feature Importance\nprint(\"Creating Feature Importance plot...\")\nplt.figure(figsize=(10, 6))\ncolors = ['skyblue', 'lightcoral', 'lightgreen', 'gold']\nbars = plt.barh(importance_df['Feature'], importance_df['Importance'], color=colors)\nplt.title('Feature Importance in Decision Tree Classifier', fontsize=16, fontweight='bold')\nplt.xlabel('Importance Score', fontsize=12)\nplt.ylabel('Features', fontsize=12)\n\n# Add value labels on bars\nfor bar, value in zip(bars, importance_df['Importance']):\n    plt.text(value + 0.01, bar.get_y() + bar.get_height()/2, \n             f'{value:.3f}', ha# Iris Species Classification using Decision Tree Classifier\n# A complete machine learning pipeline with scikit-learn",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'SyntaxError'>",
          "evalue": "incomplete input (<ipython-input-20-ee115d77d61e>, line 21)",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 21\u001b[0;36m\u001b[0m\n\u001b[0;31m    # A complete machine learning pipeline with scikit-learn\u001b[0m\n\u001b[0m                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 20
    },
    {
      "id": "66e0522d-cb77-4d67-82a8-1e06a42d9750",
      "cell_type": "code",
      "source": "# Step 10: Summary and Conclusions\nprint(\"\\n\\n10. SUMMARY AND CONCLUSIONS\")\nprint(\"-\" * 40)\nprint(f\"✓ Dataset successfully loaded with {df.shape[0]} samples and {df.shape[1]-2} features\")\nprint(f\"✓ No missing values found - data is clean\")\nprint(f\"✓ Perfect class balance with 50 samples per species\")\nprint(f\"✓ Decision Tree achieved {test_accuracy*100:.2f}% accuracy on test set\")\nprint(f\"✓ Model shows {feature_names[np.argmax(feature_importance)]} as most important feature\")\nprint(f\"✓ All three iris species classified with high precision and recall\")\n\n# Additional model validation\nif test_accuracy > 0.95:\n    print(\"✓ Excellent model performance - very high accuracy achieved!\")\nelif test_accuracy > 0.85:\n    print(\"✓ Good model performance - satisfactory accuracy achieved!\")\nelse:\n    print(\"! Model performance could be improved - consider hyperparameter tuning\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"ANALYSIS COMPLETE\")\nprint(\"=\" * 60)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\n\n10. SUMMARY AND CONCLUSIONS\n----------------------------------------\n✓ Dataset successfully loaded with 150 samples and 4 features\n✓ No missing values found - data is clean\n✓ Perfect class balance with 50 samples per species\n✓ Decision Tree achieved 93.33% accuracy on test set\n✓ Model shows PetalLengthCm as most important feature\n✓ All three iris species classified with high precision and recall\n✓ Good model performance - satisfactory accuracy achieved!\n\n============================================================\nANALYSIS COMPLETE\n============================================================\n"
        }
      ],
      "execution_count": 15
    },
    {
      "id": "87a52ba9-1791-461e-9a03-a122b9097196",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}